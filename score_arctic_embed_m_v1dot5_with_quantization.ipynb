{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6da107d-5646-4405-af1f-af31c3654556",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook demonstrates the high retrieval quality at small (128 byte) embedding vectors from the `snowflake-arctic-m-v1.5` model.\n",
    "\n",
    "We begin by loading the full 768-dimensional embeddings in full float32 precision (these precomputed embeddings are made available as a Huggingface dataset). We then demonstrate proper truncation with renormalization to unit norm, plus uniform scalar quantization to int4 datatype.\n",
    "\n",
    "## Int4 Quantization\n",
    "\n",
    "TODO: Add equations\n",
    "\n",
    "TODO: Add explation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3aed8c9-bb75-4755-aa1a-557d2084fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas torch numba pytrec-eval pyarrow tqdm huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c18971-f9f2-48b3-abdd-365a7ddcbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "\n",
    "import huggingface_hub\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytrec_eval\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from numpy.typing import NDArray\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fbd2611-b058-416a-b8d4-b6ada8e68f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config.\n",
    "EMBEDDINGS_DATASET_ID = \"Snowflake/mteb-retrieval-snowflake-arctic-embed-m-v1.5\"\n",
    "COLUMN_DOC_ID = \"DOC_ID\"\n",
    "COLUMN_QUERY_ID = \"QUERY_ID\"\n",
    "COLUMN_VECTOR = \"VECTOR_MAIN\"\n",
    "SCALAR_QUANTIZATION_LIMIT = 0.18\n",
    "TRUNCATION_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b7c154-8d79-4441-956a-3194ef5076f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions.\n",
    "\n",
    "\n",
    "#### BEGIN LOADING EMBEDDINGS ####\n",
    "\n",
    "def load_embeddings(\n",
    "    pq_paths: list[Path],\n",
    "    id_column_name: str,\n",
    "    vector_column_name: str = COLUMN_VECTOR,\n",
    "    truncate_dim: int | None = None,\n",
    "    num_read_threads: int = 10,\n",
    ") -> tuple[list[str], NDArray[np.float32]]:\n",
    "    total_rows = _total_rows(pq_paths)\n",
    "    vector_chunks = []\n",
    "    ids = []\n",
    "    with tqdm(total=total_rows, unit=\"row\", desc=\"Loading embeddings from disk\") as pbar, ThreadPool(num_read_threads) as pool:\n",
    "        table_iter = pool.imap(pq.read_table, pq_paths)\n",
    "        for table in table_iter:\n",
    "            id_chunk = table[id_column_name].to_pylist()\n",
    "            vector_chunk = _pa_vector_column_to_np_matrix(table[vector_column_name])\n",
    "            if truncate_dim is not None:\n",
    "                vector_chunk = truncate_embeddings(vector_chunk, truncate_dim)\n",
    "            assert len(id_chunk) == vector_chunk.shape[0]\n",
    "            ids.extend(id_chunk)\n",
    "            vector_chunks.append(vector_chunk)\n",
    "            pbar.update(len(id_chunk))\n",
    "    return ids, np.row_stack(vector_chunks)\n",
    "\n",
    "def _pa_vector_column_to_np_matrix(pa_array: pa.ChunkedArray) -> NDArray[np.float32]:\n",
    "    embed_dim = len(pa_array[0])\n",
    "    res = pa_array.combine_chunks().flatten().to_numpy().reshape(-1, embed_dim)\n",
    "    return cast(NDArray[np.float32], res)\n",
    "\n",
    "\n",
    "def _normalize_embeddings(embedings_matrix: NDArray[np.float32]) -> NDArray[np.float32]:\n",
    "    \"\"\"Normalize embeddings to unit norm along axis 1.\"\"\"\n",
    "    return cast(\n",
    "        NDArray[np.float32], F.normalize(torch.tensor(embedings_matrix), dim=1).numpy()\n",
    "    )\n",
    "\n",
    "def truncate_embeddings(embedings_matrix: NDArray[np.float32], dim: int) -> NDArray[np.float32]:\n",
    "    \"\"\"Truncate and renomalize embeddings to lower dimensionality.\"\"\"\n",
    "    assert dim <= embedings_matrix.shape[1]\n",
    "    return _normalize_embeddings(embedings_matrix[:, :dim])\n",
    "\n",
    "def _total_rows(pq_paths: list[Path]) -> int:\n",
    "    total = 0\n",
    "    for p in pq_paths:\n",
    "        with pq.ParquetFile(p) as pqf:\n",
    "            total += pqf.metadata.num_rows\n",
    "    return total\n",
    "\n",
    "\n",
    "#### BEGIN 4BIT QUANTIZATION ####\n",
    "\n",
    "@numba.njit(error_model=\"numpy\", parallel=True)\n",
    "def fast_4bit_uniform_scalar_quantize(\n",
    "    emb_matrix: NDArray[np.float32], limit: float\n",
    ") -> NDArray[np.uint8]:\n",
    "    num_row, num_col = emb_matrix.shape\n",
    "    assert num_col % 2 == 0\n",
    "    assert limit > 0\n",
    "    out = np.empty((num_row, num_col // 2), dtype=np.uint8)\n",
    "    bin_width = 2 * limit / 15\n",
    "    for i in numba.prange(num_row):\n",
    "        row = emb_matrix[i, :]\n",
    "        for out_j in range(num_col // 2):\n",
    "            # Pull out two values at a time.\n",
    "            in_j = out_j * 2\n",
    "            value1 = row[in_j]\n",
    "            value2 = row[in_j + 1]\n",
    "\n",
    "            # 4-bit quantize the values.\n",
    "            value1 = round(max(0, min(2 * limit, limit + value1)) / bin_width)\n",
    "            value2 = round(max(0, min(2 * limit, limit + value2)) / bin_width)\n",
    "\n",
    "            # Pack the values into a single uint8.\n",
    "            value_packed = (value1 << 4) | value2\n",
    "            out[i, out_j] = value_packed\n",
    "\n",
    "    return out\n",
    "\n",
    "def uint8_matmul(a: NDArray[np.uint8], b: NDArray[np.uint8], out=None) -> NDArray[np.int32]:\n",
    "    \"\"\"\n",
    "    NOTE: A direct `a @ b` will cause integer overflow in datatype uint8.\n",
    "    NOTE: `np.matmul(a, b, dtype=np.int32)` was ~4x slower than the `np.einsum` version on my machine.\n",
    "    \"\"\"\n",
    "    n, d = a.shape\n",
    "    d2, m = b.shape\n",
    "    assert d2 == d\n",
    "    # return np.matmul(a, b, dtype=np.int32)  # SLOW!\n",
    "    return np.einsum(\"ik, kj -> ij\", a, b, dtype=np.int32, out=out)\n",
    "\n",
    "@numba.njit(error_model=\"numpy\", parallel=True)\n",
    "def parallel_uint4_as_uint8_matmul(a: NDArray[np.uint8], b: NDArray[np.uint8]) -> NDArray[np.int32]:\n",
    "    \"\"\"Optimized multi-threaded implementation of matmul between uint4-stored-in-uint8 values.\n",
    "\n",
    "    NOTE: Loop order optimized for C-layout `a` and F-layout `b` (i.e. `a @ b.T` on C-layout `a` and `b`).\n",
    "    \"\"\"\n",
    "    n, d = a.shape\n",
    "    d2, m = b.shape\n",
    "    assert d2 == d\n",
    "    assert (a < 16).all(), \"Large value will trigger multiplication overlfow\"\n",
    "    assert (b < 16).all(), \"Large value will trigger multiplication overlfow\"\n",
    "    out = np.zeros((n, m), dtype=np.int32)\n",
    "    for i in numba.prange(n):\n",
    "        for j in range(m):\n",
    "            out[i, j] = np.sum(a[i, :] * b[:, j], dtype=np.int32)\n",
    "    return out\n",
    "\n",
    "\n",
    "def uint8_to_float_blas_matmul(a: NDArray[np.uint8], b: NDArray[np.uint8]) -> NDArray[np.int32]:\n",
    "    \"\"\"It's hard to beat the incredible optimizations built into BLAS-based f32 matmul,\n",
    "    so just type-converting to do uint8 matmul is actually pretty darn fast.\n",
    "    \"\"\"\n",
    "    return (a.astype(np.float32) @ b.astype(np.float32)).astype(np.int32)\n",
    "\n",
    "\n",
    "def unpack_4bit_to_8bit(x: NDArray[np.uint8]) -> NDArray[np.uint8]:\n",
    "    num_row, num_col_half = x.shape\n",
    "    out = np.empty((num_row, 2 * num_col_half), dtype=np.uint8)\n",
    "    out[:, 0::2] = np.right_shift(x, np.uint8(4))\n",
    "    out[:, 1::2] = np.bitwise_and(x, np.uint8(0b1111))\n",
    "    return out\n",
    "\n",
    "\n",
    "def multi_query_4bit_dotproduct(a: NDArray[np.uint8], b: NDArray[np.uint8], limit: float) -> NDArray[np.float32]:\n",
    "    n, packed_dim = a.shape\n",
    "    m, packed_dim_2 = b.shape\n",
    "    assert packed_dim == packed_dim_2\n",
    "    unpacked_dim = 2 * packed_dim\n",
    "    bin_width = 2 * limit / 15\n",
    "    a, b = unpack_4bit_to_8bit(a), unpack_4bit_to_8bit(b)\n",
    "    sum_of_sums = (np.sum(a, axis=1, dtype=np.int32)[:, None] + np.sum(b, axis=1, dtype=np.int32)[None, :]).astype(np.float32)\n",
    "    sum_of_prods = uint8_to_float_blas_matmul(a, b.T).astype(np.float32)\n",
    "    out = np.empty((n, m), dtype=np.float32)\n",
    "    out[:] = limit * limit * unpacked_dim\n",
    "    out += -limit * bin_width * sum_of_sums\n",
    "    out += bin_width * bin_width * sum_of_prods\n",
    "    return out\n",
    "\n",
    "\n",
    "@numba.njit(error_model=\"numpy\", parallel=True)\n",
    "def fast_single_query_4bit_dotproduct(\n",
    "    query_vector_4bit: NDArray[np.uint8], doc_matrix_4bit: NDArray[np.uint8], limit: float\n",
    ") -> NDArray[np.float32]:\n",
    "    num_row, num_col = doc_matrix_4bit.shape\n",
    "    assert query_vector_4bit.shape == (num_col,)\n",
    "    assert num_col % 2 == 0\n",
    "    assert limit > 0\n",
    "    out = np.empty(num_row, dtype=np.float32)\n",
    "    bin_width = 2 * limit / 15\n",
    "    for i in numba.prange(num_row):\n",
    "        row = doc_matrix_4bit[i, :]\n",
    "        sum_of_sums = np.int64(0)\n",
    "        sum_of_prods = np.int64(0)\n",
    "        for j in range(num_col):\n",
    "            # Unpack the values from this byte.\n",
    "            query_value = query_vector_4bit[j]\n",
    "            doc_value = row[j]\n",
    "            qv1 = np.right_shift(query_value, np.uint8(4))\n",
    "            dv1 = np.right_shift(doc_value, np.uint8(4))\n",
    "            qv2 = np.bitwise_and(query_value, np.uint8(0b1111))\n",
    "            dv2 = np.bitwise_and(doc_value, np.uint8(0b1111))\n",
    "\n",
    "            # Accumulate running statistics.\n",
    "            sum_of_sums += qv1 + dv1 + qv2 + dv2\n",
    "            sum_of_prods += qv1 * dv1 + qv2 * dv2\n",
    "        out[i] = (\n",
    "            limit * limit * 2 * num_col\n",
    "            - limit * bin_width * sum_of_sums\n",
    "            + bin_width * bin_width * sum_of_prods\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, error_model=\"numpy\", fastmath=True)\n",
    "def fast_multi_query_4bit_dotproduct(query_emb_quant, doc_emb_quant, limit):\n",
    "    num_query, num_col = query_emb_quant.shape\n",
    "    num_doc, num_col2 = doc_emb_quant.shape\n",
    "    assert num_col == num_col2\n",
    "    assert num_col % 2 == 0\n",
    "    assert limit > 0\n",
    "    out = np.empty((num_query, num_doc), dtype=np.float32)\n",
    "    bin_width = 2 * limit / 15\n",
    "    for q in numba.prange(num_query):\n",
    "        query_vec = query_emb_quant[q, :]\n",
    "        for i in range(num_doc):\n",
    "            doc_vec = doc_emb_quant[i, :]\n",
    "            sum_of_sums = np.uint32(0)\n",
    "            sum_of_prods = np.uint32(0)\n",
    "            for j in range(num_col):\n",
    "                # Unpack the values from this byte.\n",
    "                query_value = query_vec[j]\n",
    "                doc_value = doc_vec[j]\n",
    "                qv1 = np.right_shift(query_value, np.uint8(4))\n",
    "                dv1 = np.right_shift(doc_value, np.uint8(4))\n",
    "                qv2 = np.bitwise_and(query_value, np.uint8(0b1111))\n",
    "                dv2 = np.bitwise_and(doc_value, np.uint8(0b1111))\n",
    "    \n",
    "                # Accumulate running statistics.\n",
    "                sum_of_sums += qv1 + dv1 + qv2 + dv2\n",
    "                sum_of_prods += qv1 * dv1 + qv2 * dv2\n",
    "\n",
    "            # Convert from integer statistics back to floating point.\n",
    "            out[q, i] = (\n",
    "                limit * limit * 2 * num_col\n",
    "                - limit * bin_width * sum_of_sums\n",
    "                + bin_width * bin_width * sum_of_prods\n",
    "            )\n",
    "    return out\n",
    "\n",
    "\n",
    "#### BEGIN RETRIEVAL AND IR EVALUATION ####\n",
    "\n",
    "@numba.njit(error_model=\"numpy\", parallel=True)\n",
    "def sorted_indices_and_scores(scores: NDArray[np.float32], depth: int) -> tuple[NDArray[np.int64], NDArray[np.float32]]:\n",
    "    idx_argpartition = np.argpartition(scores, -depth, axis=1)\n",
    "    topk_indices_slice = idx_argpartition[:, -depth:]\n",
    "    topk_scores = np.take_along_axis(scores_slice, topk_indices_slice, axis=1)\n",
    "    idx_argsort = np.argsort(-topk_scores)\n",
    "    topk_indices_sorted = np.take_along_axis(topk_indices_slice, idx_argsort, axis=1)\n",
    "    topk_scores_sorted = np.take_along_axis(topk_scores, idx_argsort, axis=1)\n",
    "    return topk_indices_sorted, topk_scores_sorted\n",
    "\n",
    "\n",
    "def dense_retrieval(\n",
    "    query_ids: list[str],\n",
    "    doc_ids: list[str],\n",
    "    query_embeddings: NDArray[np.float32],\n",
    "    doc_embeddings: NDArray[np.float32],\n",
    "    retrieval_depth: int,\n",
    "    quantize_4bit_with_limit: float | None = None,\n",
    "    batch_size: int = 256,\n",
    ") -> dict[str, dict[str, float]]:\n",
    "    \"\"\"Perform dense retrieval with a set of ids and embeddings to get query results.\"\"\"\n",
    "    if quantize_4bit_with_limit is not None:\n",
    "        query_embeddings = fast_4bit_uniform_scalar_quantize(query_embeddings, quantize_4bit_with_limit)\n",
    "        doc_embeddings = fast_4bit_uniform_scalar_quantize(doc_embeddings, quantize_4bit_with_limit)\n",
    "    \n",
    "    query_results = {}\n",
    "    num_queries, num_docs = query_embeddings.shape[0], doc_embeddings.shape[0]\n",
    "    retrieval_depth = min(retrieval_depth, num_docs)\n",
    "\n",
    "    batch_slices = [slice(start_i, start_i + batch_size) for start_i in range(0, num_queries, batch_size)]\n",
    "    with tqdm(total=num_queries, desc=\"dense retrieval\", unit=\"query\") as pbar:\n",
    "        for batch_slice in batch_slices:\n",
    "            q_emb_slice = query_embeddings[batch_slice]\n",
    "            if quantize_4bit_with_limit is None:\n",
    "                scores_slice = q_emb_slice @ doc_embeddings.T\n",
    "            else:\n",
    "                scores_slice = fast_multi_query_4bit_dotproduct(q_emb_slice, doc_embeddings, quantize_4bit_with_limit)\n",
    "                \n",
    "            # Get indices and values of top-k scores.\n",
    "            topk = torch.topk(torch.tensor(scores_slice), retrieval_depth)\n",
    "            topk_indices_sorted = topk.indices.numpy()\n",
    "            topk_scores_sorted = topk.values.numpy()\n",
    "    \n",
    "            # Convert each set of scores in the slice to a top-k dictionary.\n",
    "            query_ids_slice = query_ids[batch_slice]\n",
    "            for slice_offset in range(scores_slice.shape[0]):\n",
    "                # Populate the results dictionary.\n",
    "                query_id = query_ids_slice[slice_offset]\n",
    "                sorted_doc_ids = [doc_ids[idx] for idx in topk_indices_sorted[slice_offset]]\n",
    "                query_results[query_id] = dict(zip(sorted_doc_ids, topk_scores_sorted[slice_offset].tolist()))\n",
    "            pbar.update(len(query_ids_slice))\n",
    "\n",
    "    return query_results\n",
    "\n",
    "\n",
    "def score_ir_results(\n",
    "    qrels: dict[str, dict[str, int]],\n",
    "    results: dict[str, dict[str, float]],\n",
    "    k_values: list[int],\n",
    "    ignore_identical_ids: bool = True,\n",
    "    compute_precision: bool = False,\n",
    "    round_to: int = 5,\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"Adapted from https://github.com/embeddings-benchmark/mteb/blob/dd5d61724e71b2cdba9f9cf7e01fbed1b81cb423/mteb/evaluation/evaluators/RetrievalEvaluator.py#L189  # noqa: E501\n",
    "    to ensure consistency with the oficial MTEB evaluation script (which itself\n",
    "    aims for consistency with BEIR).\n",
    "    \"\"\"\n",
    "    if ignore_identical_ids:\n",
    "        popped = []\n",
    "        for qid, rels in results.items():\n",
    "            for pid in list(rels):\n",
    "                if qid == pid:\n",
    "                    results[qid].pop(pid)\n",
    "                    popped.append(pid)\n",
    "        if len(popped) > 0:\n",
    "            logging.info(\n",
    "                f\"Ignoring {len(popped):,d} cases where query id matches \"\n",
    "                \"document id for consistency with MTEB/BEIR eval. Set \"\n",
    "                \"`ignore_identical_ids=False` to disable this behavior.\"\n",
    "            )\n",
    "\n",
    "    ndcg: Dict[str, float] = {}\n",
    "    recall: Dict[str, float] = {}\n",
    "    precision: Dict[str, float] = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        ndcg[f\"nDCG@{k}\"] = 0.0\n",
    "        recall[f\"R@{k}\"] = 0.0\n",
    "\n",
    "    ndcg_string = \"ndcg_cut.\" + \",\".join([str(k) for k in k_values])\n",
    "    recall_string = \"recall.\" + \",\".join([str(k) for k in k_values])\n",
    "    precision_string = \"P.\" + \",\".join([str(k) for k in k_values])\n",
    "    measures = {ndcg_string, recall_string}\n",
    "    if compute_precision:\n",
    "        measures.add(precision_string)\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, measures)\n",
    "    scores = evaluator.evaluate(results)\n",
    "\n",
    "    for query_id in scores.keys():\n",
    "        for k in k_values:\n",
    "            ndcg[f\"nDCG@{k}\"] += scores[query_id][\"ndcg_cut_\" + str(k)]\n",
    "            recall[f\"R@{k}\"] += scores[query_id][\"recall_\" + str(k)]\n",
    "            if compute_precision:\n",
    "                precision[f\"P@{k}\"] += scores[query_id][\"P_\" + str(k)]\n",
    "\n",
    "    for k in k_values:\n",
    "        ndcg[f\"nDCG@{k}\"] = round(ndcg[f\"nDCG@{k}\"] / len(scores), round_to)\n",
    "        recall[f\"R@{k}\"] = round(recall[f\"R@{k}\"] / len(scores), round_to)\n",
    "        if compute_precision:\n",
    "            precision[f\"P@{k}\"] = round(precision[f\"P@{k}\"] / len(scores), round_to)\n",
    "\n",
    "    return {**ndcg, **recall, **precision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3883f8-f5de-4868-bd12-920c889dd670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8005b140c714836816d0dddebca6385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 597 files:   0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the precomputed embeddings for MTEB Retrieval.\n",
    "# NOTE: The full dataset is around ~100GB.\n",
    "\n",
    "# # Example of downloading a subset of datasets.\n",
    "# dataset_subset = [\"NFCorpus\", \"FiQA2018\"]\n",
    "# embeddings_dataset_path_str = huggingface_hub.snapshot_download(\n",
    "#     repo_id=EMBEDDINGS_DATASET_ID,\n",
    "#     repo_type=\"dataset\",\n",
    "#     allow_patterns=[\"_qrels/*\"] + [f\"{x}/*\" for x in dataset_subset],\n",
    "# )\n",
    "\n",
    "embeddings_dataset_path_str = huggingface_hub.snapshot_download(\n",
    "    repo_id=EMBEDDINGS_DATASET_ID, repo_type=\"dataset\"\n",
    ")\n",
    "embeddings_dataset_path = Path(embeddings_dataset_path_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43a15d6-c3c7-4969-b7ac-63612c777be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14491dadbb7a46bfaf897d18392e6a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/57638 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcee09e3dd14e1eab6d34d4429f88e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/648 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emb_dir = embeddings_dataset_path / \"FiQA2018\" / \"embeddings\"\n",
    "doc_emb_file_paths = sorted(emb_dir.glob(\"documents*.parquet\"))\n",
    "query_emb_file_paths = sorted(emb_dir.glob(\"queries*.parquet\"))\n",
    "doc_ids, doc_emb = load_embeddings(doc_emb_file_paths, id_column_name=COLUMN_DOC_ID, truncate_dim=TRUNCATION_DIM)\n",
    "query_ids, query_emb = load_embeddings(query_emb_file_paths, id_column_name=COLUMN_QUERY_ID, truncate_dim=TRUNCATION_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d9fb01-fd7f-4738-81b8-1b17b599c6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4048a2571d304d198e945d4a1d2f9727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/648 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 99.8 ms, total: 1.23 s\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = dense_retrieval(query_ids, doc_ids, query_emb, doc_emb, retrieval_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fafc12bb-9cc3-4cb9-b7ee-e95b36d54ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40dc9cc592e4711840f6341c8de685a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/648 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.37 s, sys: 284 ms, total: 7.65 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NOTE: This code isn't super fast because even with our `numba` \"fast\" implementation above, our code for int4 matmuls is\n",
    "# much much less optimized than standard float32 matmul code behind non-int4-quantized dense retrieval.\n",
    "scores_quant = dense_retrieval(\n",
    "    query_ids,\n",
    "    doc_ids,\n",
    "    query_emb,\n",
    "    doc_emb,\n",
    "    retrieval_depth=10,\n",
    "    quantize_4bit_with_limit=SCALAR_QUANTIZATION_LIMIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d571420-8dde-4354-b569-12c2fc7362c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mteb_qrels(task_name: str) -> dict:\n",
    "    path = embeddings_dataset_path / \"_qrels\" / f\"{task_name}.json\"\n",
    "    return json.loads(path.read_text())\n",
    "\n",
    "qrel = load_mteb_qrels(\"FiQA2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c29b0412-c4cb-4ecf-8b72-1126e77488be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41671, 0.41258)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_unquant = score_ir_results(qrel, scores, k_values=[10])[\"nDCG@10\"]\n",
    "score_quant = score_ir_results(qrel, scores_quant, k_values=[10])[\"nDCG@10\"]\n",
    "score_unquant, score_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff431e1-cf6f-46d0-91b5-3582fdf3e373",
   "metadata": {},
   "source": [
    "# Single-query example\n",
    "\n",
    "For single vectors, even our `numba`-based int4 dotproduct implementation feels pretty fast (scanning 500k documents in 10ms!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "473f75ef-b3ce-404d-9218-e84ffc2b4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec = query_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11176b35-1376-4652-952b-42f65d6bf16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820 µs ± 112 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dotproduct_scores = q_vec[None, :] @ doc_emb.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d825ff58-cbe5-4ad2-969d-fc95deeb81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vec_quant = fast_4bit_uniform_scalar_quantize(q_vec[None, :], SCALAR_QUANTIZATION_LIMIT)[0]\n",
    "doc_emb_quant = fast_4bit_uniform_scalar_quantize(doc_emb, SCALAR_QUANTIZATION_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d166e92-fc16-4ff7-8b81-0862d1fbdf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 ms ± 125 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dotproduct_scores_quant = fast_single_query_4bit_dotproduct(q_vec_quant, doc_emb_quant, SCALAR_QUANTIZATION_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b259b7-5020-4274-abb8-2952ae2ca558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error μ ± σ: 3.64% ± 111.36%\n"
     ]
    }
   ],
   "source": [
    "unquant_scores = q_vec @ doc_emb.T\n",
    "quant_scores = fast_single_query_4bit_dotproduct(q_vec_quant.squeeze(), doc_emb_quant, SCALAR_QUANTIZATION_LIMIT)\n",
    "relative_error = np.abs(unquant_scores - quant_scores) / unquant_scores\n",
    "print(f\"Relative error μ ± σ: {relative_error.mean():.2%} ± {relative_error.std():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbd2e2-2277-483e-b161-7426df45c37d",
   "metadata": {},
   "source": [
    "# Score all the datasets\n",
    "\n",
    "Below we provide a reproducible implementation of int4 compressed retrieval quality scoring to show how `snowflake-arctic-embed-m-v1.5` is capable of achieving a 53.7 MTEB Retrieval score in just 128 bytes per vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "791543bb-35a2-4152-b143-2a22c4733a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring: ['ArguAna', 'CQADupstackAndroidRetrieval', 'CQADupstackEnglishRetrieval', 'CQADupstackGamingRetrieval', 'CQADupstackGisRetrieval', 'CQADupstackMathematicaRetrieval', 'CQADupstackPhysicsRetrieval', 'CQADupstackProgrammersRetrieval', 'CQADupstackStatsRetrieval', 'CQADupstackTexRetrieval', 'CQADupstackUnixRetrieval', 'CQADupstackWebmastersRetrieval', 'CQADupstackWordpressRetrieval', 'ClimateFEVER', 'DBPedia', 'FEVER', 'FiQA2018', 'HotpotQA', 'MSMARCO', 'NFCorpus', 'NQ', 'QuoraRetrieval', 'SCIDOCS', 'SciFact', 'TRECCOVID', 'Touche2020']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb9a4ce645a45cb93d4d3a798098623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArguAna\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e256653d97a4645b7f550d4728c25b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/8674 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bf694615bf4b1a820b247f152a4903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1406 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d85a7b3eee9419fb882c776863aba69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1406 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c835bcb19c406ab60e97cb6c8b9219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1406 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackAndroidRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa45ae5a3d746138ebb086113a1d1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/22998 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abea8489d654944bd85f3ced4f69078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/699 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bededf2fd2034180a60c3f7f75984863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/699 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bee4d458bb4be4824eeeb1cb1dd392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/699 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackEnglishRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28da78b2cd7f47dc8f2c1e18fd1b0e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/40221 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948192dddde348ca9b37ed0cf3dc335a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1570 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08870e264be24ede98ece4c0bb8a5df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1570 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95211fbbc4aa47e4ba32138dbb282edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1570 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackGamingRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1f192ec1824a1d8414273719bac4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/45301 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bdc1e86ce949fcab10e9214fb18dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1595 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89c80dd6e584f589499dd4fb863ac5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1595 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6432dace1c47aca400d4050e370224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1595 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackGisRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c9be266e5546c984dcaed4b9a36f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/37637 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54730e3768c749ffa473e3dec4a0cbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/885 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef0071873dc4ff496f27b411c7bdcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/885 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876554eebac149258b6729bfffcb6cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/885 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackMathematicaRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe160c0bd35463fa749784c1d771883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/16705 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c18aaf41ce249fa985a157ac750ddf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/804 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4197c37ed05e48a993046947724acbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/804 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ff3905385d44f69bc8a6f3209f6306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/804 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackPhysicsRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e5d5369883491ba47a2be4aa98ac2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/38316 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20c893f9f27464198fc08f32d42cfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1039 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefaf1dc7a584e7da88748fc9ec05780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1039 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0641835cf18f4c168a81712ee1ebc516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1039 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackProgrammersRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1068b385ff164b6cb1193f765cb9ad00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/32176 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2763f21bfd724d25806816a2702000d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/876 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be1b029bda04a74aa4a2034909ec7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/876 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845c3fdd26ce43c6842b745c0048252d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/876 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackStatsRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f67ad29807410886d3a494461e4df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/42269 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0314c121842e475bb0832c419b6282ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/652 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5df4c5100234f6db7c21e9475962010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/652 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66021f9725c847bdbbc37bc5a2a45267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/652 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackTexRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fe1af1d6654736963831e160b84bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/68184 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ff898bf353454fb46b21469c832703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/2906 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f07c1b17dd5485a8f7e67c031a46865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/2906 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0811a2a645bc4470b6514ca179adfb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/2906 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackUnixRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f2370708814ca49c2048d85ef86a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/47382 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7281e6f8ca044acea99bdfa3389ecf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1072 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaa9a7cc2c546d38ffe9af5987a3708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1072 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b0dd9fd994090b0dbba6a3a17dd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1072 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackWebmastersRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e072a3ef292460183367c1bc3098724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/17405 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827e475eb8a2483297a0fbaddc2ce127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/506 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c52fd3342c48a3bc8558b35e95688d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/506 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc148ecca15b492c8c8ffa5bfd1507ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/506 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQADupstackWordpressRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df694613abf4abca696d87ce67e73cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/48605 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e293d487da00483abc37ac22441a7496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/541 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866a0598d0554b8baca99c54a28420ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/541 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30e4e3f4cda458fb7d0d6c9d9a2abac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/541 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClimateFEVER\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101b9ba238ce40d4afd62fd82c347ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/5416593 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f522f90aa97e43babbdb963fa9f88ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1535 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c690ba38c7d24255a43254593269b96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1535 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16974db5924f49bc8e8a6463cc3c7cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1535 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBPedia\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d6685492d8448abccdda114341a47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/4635922 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664bd5090c234e93a125e331e1aee9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/400 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6274592af0054b63bb22a596482978bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/400 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65116f5175a84fc48befb565e64d7aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/400 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEVER\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc09c82c067b4ecfaef1dd40937dfac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/5416568 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161e4e951b8045359c986ec1029e06ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/6666 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22a03c3418543fda6823616569e8c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/6666 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49601df6a04f4edc8c02e48188321d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/6666 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FiQA2018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4412a7b46a4dd6bdff783848719311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/57638 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1168be922c264570b84d0e624f395102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/648 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74103b820f31494f8ace8f32dca1d5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/648 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d85c18ff285469e9fc305515d2940ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/648 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotpotQA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a607bf9c601b4e0f8aae1b4c5787888d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/5233329 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751bc20369a14b42bc0bca3e04a8e7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/7405 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab828b1ca1404e869d656e8f7b89247f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/7405 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724f90f42df148798664c6bb718a5df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/7405 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSMARCO\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eac5356dabe434eb370dca1622e70ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/8841823 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2644d55037024628b9a5f77e2bbaea8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/6980 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e19cd00ee840f1a45ab7424891e95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/6980 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bf281aad0f41a8822d9581f0f13ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/6980 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFCorpus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccea1960563f48939bd1442a6fc283ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/3633 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96242c5d58734d6da48aa5ca4c8f9226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/323 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb03fd9eeab34b9b928316c761bf624e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/323 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8849bbe912f4b6d9fd77a8712775583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/323 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NQ\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7778eed5c24c4ba493e085e772e2f91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/2681468 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb1a79477284dc49960e03ad983c50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/3452 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d462c5fb6c4450b6d673f0ae48c676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/3452 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2e2649a098472ab6156384ee8f8f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/3452 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuoraRetrieval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6690a4622e4742a099d251d77933df5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/522931 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f24261e9cb47d49bde09258e1b93b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/10000 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ed6f4f26274180b5dc39ae9cd0e4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/10000 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14e331089344ab2aa88a8fb507cf880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/10000 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIDOCS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1852ac908a954c0490b1b2bd391596b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/25657 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a937bba1e0e74693bdad937324eaf090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/1000 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f80562aea1e4ce6a3c22d92256b331e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1000 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35edce4c9cd04fa1b5f0af2019fae23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/1000 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciFact\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d24c9b05ef436698c5d40791408d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/5183 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b0afc610648f981a12512e3900f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/300 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10a6333c893419abf1fd3f1ed3f427e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/300 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7a8a2e93dc46898f36ff36fddc3b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/300 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRECCOVID\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56989ad1ccb4e658ef70d80507bf591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/171332 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5804b8c3fb2541eb9f86b469f7d6a099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/50 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe31ced7a7143f386e7a531da63afca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/50 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7c47c522e947f5b90cc9b1e9a50719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/50 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touche2020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c5859883bb49abb101e4b3cf05a610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/382545 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23385121d64744c3b04a25e8cfc50958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading embeddings from disk:   0%|          | 0/49 [00:00<?, ?row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23351503899473fbd94409da0f525e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/49 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b4f1750b454c17ab195b2ab5b3a66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dense retrieval:   0%|          | 0/49 [00:00<?, ?query/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = [p.parent.name for p in sorted(embeddings_dataset_path.glob(\"*/embeddings\"))]\n",
    "print(f\"Scoring: {names}\")\n",
    "ndcg10_scores_unquantized = {}\n",
    "ndcg10_scores_quantized = {}\n",
    "for name in tqdm(names):\n",
    "    print(name)\n",
    "    emb_dir = embeddings_dataset_path / name / \"embeddings\"\n",
    "    doc_emb_file_paths = sorted(emb_dir.glob(\"documents*.parquet\"))\n",
    "    query_emb_file_paths = sorted(emb_dir.glob(\"queries*.parquet\"))\n",
    "    doc_ids, doc_emb = load_embeddings(doc_emb_file_paths, id_column_name=COLUMN_DOC_ID, truncate_dim=TRUNCATION_DIM)\n",
    "    query_ids, query_emb = load_embeddings(query_emb_file_paths, id_column_name=COLUMN_QUERY_ID, truncate_dim=TRUNCATION_DIM)\n",
    "    qrel = load_mteb_qrels(name)\n",
    "    scores = dense_retrieval(query_ids, doc_ids, query_emb, doc_emb, 10)\n",
    "    scores_quant = dense_retrieval(query_ids, doc_ids, query_emb, doc_emb, 10, SCALAR_QUANTIZATION_LIMIT)\n",
    "    ndcg10_scores_unquantized[name] = score_ir_results(qrel, scores, k_values=[10])[\"nDCG@10\"]\n",
    "    ndcg10_scores_quantized[name] = score_ir_results(qrel, scores_quant, k_values=[10])[\"nDCG@10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55b746d9-1dd5-4424-9411-4e45181de39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unquantized</th>\n",
       "      <th>quantized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ArguAna</th>\n",
       "      <td>0.584760</td>\n",
       "      <td>0.579530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CQADupstackRetrieval</th>\n",
       "      <td>0.442101</td>\n",
       "      <td>0.433434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClimateFEVER</th>\n",
       "      <td>0.362290</td>\n",
       "      <td>0.360630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBPedia</th>\n",
       "      <td>0.448260</td>\n",
       "      <td>0.437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEVER</th>\n",
       "      <td>0.872240</td>\n",
       "      <td>0.865900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiQA2018</th>\n",
       "      <td>0.416710</td>\n",
       "      <td>0.412580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HotpotQA</th>\n",
       "      <td>0.691740</td>\n",
       "      <td>0.680110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSMARCO</th>\n",
       "      <td>0.412490</td>\n",
       "      <td>0.405980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFCorpus</th>\n",
       "      <td>0.357990</td>\n",
       "      <td>0.357160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NQ</th>\n",
       "      <td>0.616690</td>\n",
       "      <td>0.610140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuoraRetrieval</th>\n",
       "      <td>0.871700</td>\n",
       "      <td>0.868360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIDOCS</th>\n",
       "      <td>0.212350</td>\n",
       "      <td>0.208740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SciFact</th>\n",
       "      <td>0.698110</td>\n",
       "      <td>0.694080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRECCOVID</th>\n",
       "      <td>0.833940</td>\n",
       "      <td>0.832810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Touche2020</th>\n",
       "      <td>0.313680</td>\n",
       "      <td>0.312450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      unquantized  quantized\n",
       "ArguAna                  0.584760   0.579530\n",
       "CQADupstackRetrieval     0.442101   0.433434\n",
       "ClimateFEVER             0.362290   0.360630\n",
       "DBPedia                  0.448260   0.437000\n",
       "FEVER                    0.872240   0.865900\n",
       "FiQA2018                 0.416710   0.412580\n",
       "HotpotQA                 0.691740   0.680110\n",
       "MSMARCO                  0.412490   0.405980\n",
       "NFCorpus                 0.357990   0.357160\n",
       "NQ                       0.616690   0.610140\n",
       "QuoraRetrieval           0.871700   0.868360\n",
       "SCIDOCS                  0.212350   0.208740\n",
       "SciFact                  0.698110   0.694080\n",
       "TRECCOVID                0.833940   0.832810\n",
       "Touche2020               0.313680   0.312450"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ndcg10 = pd.DataFrame({\"unquantized\": ndcg10_scores_unquantized, \"quantized\": ndcg10_scores_quantized})\n",
    "\n",
    "# Cache results to CSV.\n",
    "df_ndcg10.to_csv(\"ndcgs_validation.csv\")\n",
    "\n",
    "# Roll up CQA Dupstack Retrieval.\n",
    "is_cqa = df_ndcg10.index.to_series().str.startswith(\"CQA\")\n",
    "cqa_mean = df_ndcg10.loc[is_cqa].mean().to_frame().T\n",
    "cqa_mean.index = [\"CQADupstackRetrieval\"]\n",
    "df_ndcg10 = pd.concat([df_ndcg10.loc[~is_cqa], cqa_mean]).sort_index()\n",
    "\n",
    "# Show scores across MTEB retrieval.\n",
    "df_ndcg10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f4587e9-b0a4-4c08-9ff2-b49215b0722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unquantized    0.542337\n",
       "quantized      0.537260\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print mean MTEB Retrieval scores.\n",
    "df_ndcg10.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3afb8c-dd02-44e9-9fc3-2e4e9a9c4dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
