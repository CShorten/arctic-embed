{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc2a0890-910e-4dca-9471-f80974931ab3",
   "metadata": {},
   "source": [
    "# This is a playground notebook\n",
    "\n",
    "In order to evaluate int4 compression, we spent some time trying to get a decently fast matrix multiply operation implemented using `numpy` and `numba`. Unfortunately it was quite hard to compete with the performance of built-in `matmul` in `numpy` due to that function relying on very well optimized BLAS routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce61c9f1-5404-4930-9e3d-efce115a6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "jit = numba.njit(error_model=\"numpy\", fastmath=True)\n",
    "ks = 16  # Kernel size.\n",
    "\n",
    "# Test data.\n",
    "n, m, d = 256, 4 * 4096, 256\n",
    "rng = np.random.default_rng(0)\n",
    "a = rng.choice(15, (n, d)).astype(np.uint8)\n",
    "b = rng.choice(15, (m, d)).astype(np.uint8).T\n",
    "\n",
    "@jit\n",
    "def uint8_matmul(a: NDArray[np.uint8], b: NDArray[np.uint8]) -> NDArray[np.uint32]:\n",
    "    \"\"\"Optimized multi-threaded implementation of matmul between uint4-stored-in-uint8 values.\"\"\"\n",
    "    n, d = a.shape\n",
    "    d2, m = b.shape\n",
    "    assert d2 == d\n",
    "    assert (a < 16).all(), \"Large value will trigger multiplication overlfow\"\n",
    "    assert (b < 16).all(), \"Large value will trigger multiplication overlfow\"\n",
    "    out = np.empty((n, m), dtype=np.uint32)\n",
    "    for i in range(n):\n",
    "        row = a[i, :]\n",
    "        for j in range(m):\n",
    "            col = b[:, j]\n",
    "            tmp = np.uint32(0)\n",
    "            for k in range(d):\n",
    "                tmp += row[k] * col[k]\n",
    "            out[i, j] = tmp\n",
    "    return out\n",
    "\n",
    "@jit\n",
    "def _mm_uint8_kernel(out: NDArray[np.uint32], a: NDArray[np.uint8], b: NDArray[np.uint8]) -> NDArray[np.uint32]:\n",
    "    tmp = np.uint32(0)\n",
    "    for i in range(ks):\n",
    "        row = a[i, :]\n",
    "        for j in range(ks):\n",
    "            col = b[:, j]\n",
    "            tmp = np.uint32(0)\n",
    "            for k in range(ks):\n",
    "                tmp += row[k] * col[k]\n",
    "            out[i, j] += tmp\n",
    "    return out\n",
    "\n",
    "@jit\n",
    "def mm_uint8_tiled(a: NDArray[np.uint8], b: NDArray[np.uint8]) -> NDArray[np.uint32]:\n",
    "    n, d = a.shape\n",
    "    d2, m = b.shape\n",
    "    assert (a < 16).all(), \"Large value will trigger multiplication overlfow\"\n",
    "    assert (b < 16).all(), \"Large value will trigger multiplication overlfow\"\n",
    "    assert d == d2\n",
    "    assert n % ks == 0\n",
    "    assert m % ks == 0\n",
    "    assert d % ks == 0\n",
    "    out = np.zeros((n, m), dtype=np.uint32)\n",
    "    n_chunks = n // ks\n",
    "    m_chunks = m // ks\n",
    "    d_chunks = d // ks\n",
    "    for ijp in range(n_chunks * m_chunks):\n",
    "        i, j = divmod(ijp, m_chunks)\n",
    "        i_start = i * ks\n",
    "        i_end = i_start + ks\n",
    "        j_start = j * ks\n",
    "        j_end = j_start + ks\n",
    "        out_chunk = out[i_start:i_end, j_start:j_end]\n",
    "        for k in range(d_chunks):\n",
    "            k_start = k * ks\n",
    "            k_end = k_start + ks\n",
    "            a_chunk = a[i_start:i_end, k_start:k_end]\n",
    "            b_chunk = b[k_start:k_end, j_start:j_end]\n",
    "            _mm_uint8_kernel(out_chunk, a_chunk, b_chunk)\n",
    "    return out\n",
    "\n",
    "\n",
    "def mm_einsum(a: NDArray[np.uint8], b: NDArray[np.uint8]) -> NDArray[np.uint32]:\n",
    "    return np.einsum(\"ij, jk -> ik\", a, b, dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168e917-4ebe-4295-af32-2f1bc2cb5a9e",
   "metadata": {},
   "source": [
    "## Trying to beat BLAS-based fp32 matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600dfe33-e872-4a2b-8db0-800568a5bd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = (a.astype(np.float32) @ b.astype(np.float32)).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890c500a-773c-4aa0-a24e-09f2a3527a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5 ms ± 3.15 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = (a.astype(np.float32) @ b.astype(np.float32)).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc0465-ccee-43bb-9f34-e3d7620784ef",
   "metadata": {},
   "source": [
    "## My attempts\n",
    "(note: single-threaded, so I'd happy even being 1/10 as fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05be9ce9-3188-47bf-929f-ec0a1b8e25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = uint8_matmul(a, b)\n",
    "assert np.all(o1 == ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5edc244-62da-455c-b4af-b66080716594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 ms ± 16.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = uint8_matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fff9a4-5235-4c5e-a670-ee724f9ab882",
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = mm_uint8_tiled(a, b)\n",
    "assert np.all(o2 == ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a228bc-edc4-47b9-a222-ad3f40e1d144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 ms ± 3.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = mm_uint8_tiled(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f19255a-e36f-418e-8a03-586b2e8d34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3 = mm_einsum(a, b)\n",
    "assert np.all(o3 == ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfae33a5-8517-4740-a889-3ba9900f0796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 ms ± 2.33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = mm_einsum(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27ad3f-cf36-4684-a3e7-6be587cee968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3dcad-81de-4b8e-86df-346efbc8dc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
